name: Deploy Static Website with Yandex CLI

# ----------------------------------------------------------------------
# Trigger: Runs the workflow when code is pushed to the 'main' branch
# ----------------------------------------------------------------------
on:
  push:
    branches:
      - main
  workflow_dispatch:

# ----------------------------------------------------------------------
# Jobs
# ----------------------------------------------------------------------
jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout: Fetches the code from the repository
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      # 2. Setup Tools - Install Yandex CLI, MinIO Client (mc), and jq
      - name: Install Deployment Dependencies
        run: |
          # Install 'jq' (JSON parser)
          sudo apt-get update
          sudo apt-get install -y jq
          
          # Install Yandex Cloud CLI (yc)
          curl -sS https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash
          echo "$HOME/yandex-cloud/bin" >> $GITHUB_PATH

          # Install MinIO Client (mc)
          curl -sS https://dl.min.io/client/mc/release/linux-amd64/mc -o /usr/local/bin/mc
          chmod +x /usr/local/bin/mc

      # 3. Deploy using Yandex Cloud CLI (yc)
      - name: Deploy Static Files via Yandex CLI and MinIO Client
        run: |
          # Define variables
          BUCKET_NAME="family-tree-ya"
          ROOT_FOLDER="docs"

          # 3a. Create the credentials file from the GitHub Secret
          echo '${{ secrets.YC_SA_CREDENTIALS }}' > /tmp/sa-credentials.json
          
          # 3b. Configure MC for S3 authentication (The fix is using --api S3v4)
          /usr/local/bin/mc alias set s3 --api S3v4 https://storage.yandexcloud.net \
            "$(jq -r '.accessKeyId' /tmp/sa-credentials.json)" \
            "$(jq -r '.secretAccessKey' /tmp/sa-credentials.json)"

          # 3c. Clear the bucket
          echo "Clearing existing content in bucket: $BUCKET_NAME"
          /usr/local/bin/mc rm --recursive --force s3/$BUCKET_NAME || true

          # 3d. Upload files recursively with correct Content-Type attributes (using 'find' for nested folders)
          echo "Uploading files from $ROOT_FOLDER to $BUCKET_NAME"

          # HTML Files: Find all HTML files and set Content-Type: text/html
          find $ROOT_FOLDER -name '*.html' -print0 | xargs -0 -I {} \
            /usr/local/bin/mc cp --attr 'Content-Type=text/html,Cache-Control=public,max-age=300' {} s3/$BUCKET_NAME/{}

          # CSS Files (in docs/styles/): Find all CSS files and set Content-Type: text/css
          find $ROOT_FOLDER -name '*.css' -print0 | xargs -0 -I {} \
            /usr/local/bin/mc cp --attr 'Content-Type=text/css,Cache-Control=public,max-age=31536000,immutable' {} s3/$BUCKET_NAME/{}
            
          # JS Files (in docs/js/): Find all JS files and set Content-Type: application/javascript
          find $ROOT_FOLDER -name '*.js' -print0 | xargs -0 -I {} \
            /usr/local/bin/mc cp --attr 'Content-Type=application/javascript,Cache-Control=public,max-age=31536000,immutable' {} s3/$BUCKET_NAME/{}
            
          # Other Files (Images, Data, PDF, etc.): Uses standard recursive copy for nested folders not handled by 'find'
          /usr/local/bin/mc cp --recursive $ROOT_FOLDER/bio s3/$BUCKET_NAME/bio/ || true
          /usr/local/bin/mc cp --recursive $ROOT_FOLDER/data s3/$BUCKET_NAME/data/ || true
          /usr/local/bin/mc cp --recursive $ROOT_FOLDER/images s3/$BUCKET_NAME/images/ || true
          /usr/local/bin/mc cp $ROOT_FOLDER/*.pdf s3/$BUCKET_NAME/ || true

      # 4. Post-Upload Confirmation
      - name: Deployment Success
        run: echo "Successfully deployed static files to Yandex Object Storage."